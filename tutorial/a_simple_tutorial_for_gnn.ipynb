{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc84868",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    " \n",
    "class GCNLayer(nn.Module):\n",
    " \n",
    "    def __init__(self,c_in,c_out):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        :param c_in: 输入特征\n",
    "        :param c_out: 输出特征\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.projection = nn.Linear(c_in,c_out); #线性层\n",
    "        \n",
    "    def forward(self,node_feats,adj_matrix):\n",
    "        \"\"\"\n",
    "        输入\n",
    "        :param node_feats: 节点特征表示，大小为[batch_size,num_nodes,c_in]\n",
    "        :param adj_matrix: 邻接矩阵：[batch_size,num_nodes,num_nodes]\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_neighbors = adj_matrix.sum(dim=-1,keepdims=True) #各节点的邻居数\n",
    "        node_feats = self.projection(node_feats)# 将特征转化为消息\n",
    "        #各邻居节点消息求和并求平均\n",
    "        node_feats = torch.bmm(adj_matrix,node_feats)\n",
    "        node_feats = node_feats / num_neighbors\n",
    "        \n",
    "        return node_feats\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2768f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a79a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feats = torch.arange(8,\n",
    "dtype=torch.float32).view(1,4,2)\n",
    "adj_matrix = torch.Tensor([[[1,1,0,0],\n",
    "            [1,1,1,1],\n",
    "            [0,1,1,1],\n",
    "            [0,1,1,1]]])\n",
    "print(\"节点特征：\\n\",node_feats)\n",
    "print(\"添加自链接的邻接矩阵：\\n\",adj_matrix)\n",
    "\n",
    "layer = GCNLayer(c_in=2, c_out=2)\n",
    "# 初始化权重矩阵\n",
    "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
    "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
    "\n",
    "# 将节点特征和添加自连接的邻接矩阵输入 GCN 层\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix)\n",
    "\n",
    "print(\"节点特征:\\n\", node_feats)\n",
    "print(\"添加自连接的邻接矩阵:\\n\", adj_matrix)\n",
    "print(\"节点输出特征:\\n\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bd67e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193c11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1c02e7c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "693f350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "class GATLayer(nn.Module):\n",
    " \n",
    "    def __init__(self,c_in,c_out,\n",
    "                num_heads=1, concat_heads=True, alpha=0.2):\n",
    "        \"\"\"\n",
    "        :param c_in: 输入特征维度\n",
    "        :param c_out: 输出特征维度\n",
    "        :param num_heads: 多头的数量\n",
    "        :param concat_heads: 是否拼接多头计算的结果\n",
    "        :param alpha: LeakyReLU的参数\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = num_heads\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads ==0,\"输出特征数必须是头数的倍数！\"\n",
    "            c_out = c_out // num_heads\n",
    " \n",
    "        #参数\n",
    "        self.projection = nn.Linear(c_in,c_out*num_heads) #有几个头，就需要将c_out扩充几倍\n",
    "        self.a = nn.Parameter(torch.Tensor(num_heads,2*c_out)) #用于计算注意力的参数，由于对两节点拼接后的向量进行操作，所以2*c_out\n",
    "        self.leakrelu = nn.LeakyReLU(alpha) #激活层\n",
    " \n",
    "        #参数初始化\n",
    "        nn.init.xavier_uniform_(self.projection.weight.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    " \n",
    "    def forward(self,node_feats,adj_matrix,print_attn_probs=False):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "        :param self:\n",
    "        :param node_feats: 节点的特征表示\n",
    "        :param adj_matrix: 邻接矩阵\n",
    "        :param print_attn_probs: 是否打印注意力\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        batch_size,num_nodes = node_feats.size(0),node_feats.size(1)\n",
    "\n",
    "        #将节点初始输入进行权重运算\n",
    "        node_feats = self.projection(node_feats)\n",
    "        #扩展出多头数量的维度\n",
    "        node_feats = node_feats.view(batch_size,num_nodes,self.num_heads,-1)\n",
    "\n",
    "        # 获取所有顶点对拼接而成的特征向量 a_input\n",
    "        edges = adj_matrix.nonzero(as_tuple=False)  # 返回所有邻接矩阵中值不为 0 的 index，即所有连接的边对应的两个顶点\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)  # 将所有 batch_size 的节点拼接\n",
    "\n",
    "        edge_indices_row = edges[:, 0] * batch_size + edges[:, 1]  # 获取边对应的第一个顶点 index\n",
    "        edge_indices_col = edges[:, 0] * batch_size + edges[:, 2]  # 获取边对应的第二个顶点 index\n",
    "\n",
    "        a_input = torch.cat([\n",
    "        torch.index_select(input=node_feats_flat, index=edge_indices_row, dim=0), # 基于边对应的第一个顶点的 index 获取其特征值\n",
    "            torch.index_select(input=node_feats_flat, index=edge_indices_col, dim=0)  # 基于边对应的第二个顶点的 index 获取其特征值\n",
    "        ], dim=-1)  # 两者拼接\n",
    "\n",
    "        # 基于权重 a 进行注意力计算\n",
    "        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a)\n",
    "        # LeakyReLU 计算\n",
    "        attn_logits = self.leakrelu(attn_logits)\n",
    "\n",
    "        # 将注意力权转换为矩阵的形式\n",
    "        attn_matrix = attn_logits.new_zeros(adj_matrix.shape + (self.num_heads,)).fill_(-9e15)\n",
    "        attn_matrix[adj_matrix[..., None].repeat(1, 1, 1, self.num_heads) == 1] = attn_logits.reshape(-1)\n",
    "\n",
    "        # Softmax 计算转换为概率\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "        if print_attn_probs:\n",
    "            print(\"注意力权重:\\n\", attn_probs.permute(0, 3, 1, 2))\n",
    "        # 对每个节点进行注意力加权相加的计算\n",
    "        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n",
    "\n",
    "        # 根据是否将多头的计算结果拼接与否进行不同操作\n",
    "        if self.concat_heads:  # 拼接\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:  # 平均\n",
    "            node_feats = node_feats.mean(dim=2)\n",
    "\n",
    "        return node_feats "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfa146c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8138d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = GATLayer(2, 2, num_heads=2)\n",
    "layer.projection.weight.data = torch.Tensor([[1., 0.], [0., 1.]])\n",
    "layer.projection.bias.data = torch.Tensor([0., 0.])\n",
    "layer.a.data = torch.Tensor([[-0.2, 0.3], [0.1, -0.1]])\n",
    "node_feats = torch.arange(8, dtype=torch.float32).view(1, 4, 2)\n",
    "adj_matrix = torch.Tensor([[[1, 1, 0, 0],\n",
    "                                    [1, 1, 1, 1],\n",
    "                                    [0, 1, 1, 1],\n",
    "                                    [0, 1, 1, 1]]])\n",
    "with torch.no_grad():\n",
    "    out_feats = layer(node_feats, adj_matrix, print_attn_probs=True)\n",
    "\n",
    "\n",
    "print(\"节点特征:\\n\", node_feats)\n",
    "print(\"添加自连接的邻接矩阵:\\n\", adj_matrix)\n",
    "print(\"节点输出特征:\\n\", out_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3431ba8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0770fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "# 基于节点的index表示边\n",
    "#[0,1,1,2]表示出发的节点index\n",
    "#[1,0,2,1]表示到达index\n",
    "edge_index = torch.tensor([[0,1,1,2],\n",
    "                           [1,0,2,1]],dtype=torch.long)\n",
    "x = torch.tensor([[-1],[0],[1]],dtype=torch.float)#节点的特征矩阵，有3个节点，特征维度为1\n",
    " \n",
    "data = Data(x=x,edge_index = edge_index) #初始化图\n",
    "print(data)#查看图属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d94789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    " \n",
    "# 导入数据集\n",
    "dataset = TUDataset(\n",
    "    # 指定数据集的存储位置\n",
    "    # 如果指定位置没有相应的数据集\n",
    "    # PyG会自动下载\n",
    "    root='ENZYMES/',\n",
    "    # 要使用的数据集\n",
    "    name='ENZYMES',\n",
    ")\n",
    "# 数据集的长度\n",
    "print(len(dataset))\n",
    "# 数据集的类别数\n",
    "print(dataset.num_classes)\n",
    "# 数据集中节点属性向量的维度\n",
    "print(dataset.num_node_features)\n",
    "# 600个图，我们可以根据索引选择要使用哪个图\n",
    "data = dataset[100]\n",
    "print(data)\n",
    "# 随机打乱数据集\n",
    "dataset = dataset.shuffle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312671e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True) # 批次大小为 32，并且数据的顺序随机打乱\n",
    "\n",
    "for batch in loader:\n",
    "    print(\"一批数据：\",batch)\n",
    "    print(\"一批数据量：\",batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "dataset = ShapeNet(root='Airplane', categories=['Airplane'])\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f28090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "dataset = ShapeNet(root='Airplane', categories=['Airplane'],\n",
    "                    pre_transform=T.KNNGraph(k=6)) # 进行 KNN 聚类操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db53662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " \n",
    "def visualize_networkx(graph, color):\n",
    "    plt.figure(figsize=(8,8)) # 设定图画区域大小\n",
    "    nx.draw_networkx(graph, with_labels=False,node_color=color) # 画图\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186af7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import to_networkx\n",
    " \n",
    "dataset = KarateClub()[0] # 取图数据集\n",
    "G = to_networkx(dataset,to_undirected=True) # 转化为 networkx\n",
    "visualize_networkx(G, color=dataset.y) # 画图"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
